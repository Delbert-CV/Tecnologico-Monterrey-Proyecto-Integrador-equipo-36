{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64209f1",
   "metadata": {},
   "source": [
    "# Reporte de problemas fitosanitarios en plantaciones de agave\n",
    "--------------------\n",
    "\n",
    "## Equipo 36\n",
    "\n",
    "| Nombre | Matrícula |\n",
    "| ------ | --------- |\n",
    "| André Martins Cordebello | A00572928 |\n",
    "| Enrique Eduardo Solís Da Costa | A00572678 |\n",
    "| Delbert Francisco Custodio Vargas | A01795613 |\n",
    "\n",
    "## Avance 2: Feature engineering\n",
    "\n",
    "- Crear nuevas características para mejorar el rendimiento de los modelos.\n",
    "- Mitigar el riesgo de características sesgadas y acelerar la convergencia de algunos algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a992969",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8c324",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141355a",
   "metadata": {},
   "source": [
    "Durante el avance 1 fue posible comprender ciertos comportamientos de nuestro dataset, así como la selección de columnas que sí aportaban información para entender de mejor manera las características de infección de gorgojos del agave en predios del mismo.\n",
    "\n",
    "Con esto, usando como base los datasets compartidos por la CNIT fue posible obtener el dataset llamada `all_historic_captures.xlsx`, el cual contiene información del 2014 a Agosto de 2025 sobre el nivel de incidencia o infección encontrado  en predios de agave. Estas muestras se obtuvieron con base a las condiciones definidas en el **Manual Operativo de la campaña contra plagas reglamentadas del Agave**, disponible en https://www.gob.mx/cms/uploads/attachment/file/234136/Manual_Operativo_de_la_campa_a_contra_plagas_reglamentadas_del_agave_2017.compressed.pdf, lo cual fue confirmado por nuestro Sponsor (CNIT).\n",
    "\n",
    "Por lo anterior, el objetivo principal de este proyecto integrador es el desarrollo de un ChatBot el cual:\n",
    "\n",
    "- Pueda recibir reportes que incluyan ubicación, breve descripción de lo encontrado, fotografías y clasificación de riesgo de parte del cuerpo técnico y ciudadanía en general.\n",
    "- Este ChatBot también debe tener la capacidad de responder y alertar a los usuarios sobre focos de infección reportados o confirmados en las cercanías.\n",
    "\n",
    "La recepción de esta información es importante ya que permitirá tomar decisiones sobre lo que las brigadas de desinfección deben atacar primero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65f675",
   "metadata": {},
   "source": [
    "Por lo anterior, durante nuestro EDA (análisis exploratorio) encontramos los siguientes hallazgos:\n",
    "\n",
    "- La captura de gorgojos del agave en las trampas tiende a aumentar en épocas lluviosas.\n",
    "- Los focos de infección severos y moderados tienen una dispersión geográfica menor.\n",
    "- No es normal encontrar predios de más de 8 años de antiguedad, lo que nos da una idea de cuáles predios podrían estar posiblemente abandonados.\n",
    "- La mayor densidad de trampas se encuentra en el estado de Jalisco.\n",
    "- No es normal encontrar focos severos de infección, pero la presencia de éstos aumenta en la época lluviosa. Es posible confirmar que los casos severos de infección son casos atípicos, ya que el valor del percentil 95 se encuentra en 17.5 capturas por trampa.\n",
    "- Durante la pandemia (2020 a 2024 aproximadamente), el muestreo de las trampas colocados no fue tan constante como en años posteriores o previos a la pandemia. Esto causa un efecto de sesgo en nuestro dataset.\n",
    "\n",
    "\n",
    "Y al transformar un poco nuestro dataset obtuvimos estas columnas finales:\n",
    "\n",
    "| Feature  | Tipo | Notas |\n",
    "| -------  | ---- | ----- |\n",
    "| tramp_id | object | Es el ID único que se le da a la trampa al colocarse en alguna parcela o predio. Una misma trampa puede colocarse en distintos predios, pero la identificación de la misma cambia acorde a dónde se colocó. |\n",
    "| sampling_date | datetime64[ns] | Es la fecha en la que se llevó a cabo el conteo de cadáveres de gorgojo en la trampa.|\n",
    "| lat y lon | float64 | La `latitud` y `longitud` permiten conocer la ubicación de donde se llevó a cabo el muestreo. |\n",
    "| municipality | object | Municipio al que pertenecía la trampa al momento de hacer el muestreo. |\n",
    "| square_area | float64 | Area que cubre el predio donde se colocó la trampa. |\n",
    "| plantation_age | float64 | Años que una plantación de agave tiene desde la última purga. |\n",
    "| capture_count | float64 | Cantidad de gorgojos del agave encontrados dentro de la trampa. |\n",
    "| state | object | Estado de México donde se encontraba la trampa colocada. |\n",
    "| severity | object | lLa severidad de la infestación encontrada durante el muestreo. Estos niveles fueron definidos por la SICAFI.|\n",
    "| Month | int32 | Mes en que se llevó a cabo el muestreo de la trampa. |\n",
    "| Year | int32 | Año en que se llevó a cabo el muestreo de la trampa. |\n",
    "| MonthName | object | Nombre del   mes en que se llevó a cabo el muestreo de la trampa. |\n",
    "| MonthYear | datetime64[ns] |  Combinación del año y mes en que se llevó a cabo el muestreo de la trampa. Esta ya es una característica creada a partir de otras columnas del Dataset. |\n",
    "\n",
    "Con esto, estaremos trabajando la ingeniería de característiscas con base en estas columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5124de",
   "metadata": {},
   "source": [
    "### Librerías  a importar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423bba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b290f6",
   "metadata": {},
   "source": [
    "### Cargamos el dataset obtenido anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1525496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tramp_id</th>\n",
       "      <th>sampling_date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>municipality</th>\n",
       "      <th>square_area</th>\n",
       "      <th>plantation_age</th>\n",
       "      <th>capture_count</th>\n",
       "      <th>state</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146_THUE13-11-023-0637T01</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>20.401984</td>\n",
       "      <td>-101.702729</td>\n",
       "      <td>PÉNJAMO</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>GUANAJUATO</td>\n",
       "      <td>1-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146_THUE13-11-023-0637T01</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>20.401984</td>\n",
       "      <td>-101.702729</td>\n",
       "      <td>PÉNJAMO</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GUANAJUATO</td>\n",
       "      <td>1-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146_THUE13-11-023-0637T01</td>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>20.401984</td>\n",
       "      <td>-101.702729</td>\n",
       "      <td>PÉNJAMO</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GUANAJUATO</td>\n",
       "      <td>1-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146_THUE13-11-023-0637T01</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>20.401984</td>\n",
       "      <td>-101.702729</td>\n",
       "      <td>PÉNJAMO</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>GUANAJUATO</td>\n",
       "      <td>1-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146_THUE13-11-023-0637T01</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>20.401984</td>\n",
       "      <td>-101.702729</td>\n",
       "      <td>PÉNJAMO</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>GUANAJUATO</td>\n",
       "      <td>1-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tramp_id sampling_date        lat         lon  \\\n",
       "0  146_THUE13-11-023-0637T01    2022-07-21  20.401984 -101.702729   \n",
       "1  146_THUE13-11-023-0637T01    2022-04-19  20.401984 -101.702729   \n",
       "2  146_THUE13-11-023-0637T01    2022-02-25  20.401984 -101.702729   \n",
       "3  146_THUE13-11-023-0637T01    2022-02-14  20.401984 -101.702729   \n",
       "4  146_THUE13-11-023-0637T01    2022-05-18  20.401984 -101.702729   \n",
       "\n",
       "  municipality  square_area  plantation_age  capture_count       state  \\\n",
       "0      PÉNJAMO         1.75               0            8.0  GUANAJUATO   \n",
       "1      PÉNJAMO         1.75               0            5.0  GUANAJUATO   \n",
       "2      PÉNJAMO         1.75               0            5.0  GUANAJUATO   \n",
       "3      PÉNJAMO         1.75               0            4.0  GUANAJUATO   \n",
       "4      PÉNJAMO         1.75               0            6.0  GUANAJUATO   \n",
       "\n",
       "  severity  \n",
       "0     1-25  \n",
       "1     1-25  \n",
       "2     1-25  \n",
       "3     1-25  \n",
       "4     1-25  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de dataset\n",
    "all_historic_captures_df = pd.read_excel( \"all_historic_captures.xlsx\", sheet_name=\"historic_captures\", header= 0)\n",
    "\n",
    "# Eliminamos las columnas que usamos para llevar a cabo una mejor comprensión en el EDA,\n",
    "# esto porque debemos decidir más adelante si serán necesarias para nuestro proceso de FE.\n",
    "all_historic_captures_df.drop(labels=['Month', 'Year', 'MonthName', 'MonthYear', 'plantation_age_group', 'surface_group', 'no_area'],axis=1, inplace=True)\n",
    "\n",
    "all_historic_captures_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf3c8b",
   "metadata": {},
   "source": [
    "### `Feature engineering` sobre `square_area`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24517029",
   "metadata": {},
   "source": [
    "Al revisar nuevamente los valores de `square_area` (o `Superficie (ha)` originalmente), es posible notar que casi el 48% de éstos es igual a `0.00`. Esto, como discutimos con anterioridad, indica que durante el proceso de muestreo de años previos a 2024 y 2025 no hubo un control de calidad para mitigar la falta de información en esta columna. Esto fue confirmado por nuestro Sponsor.\n",
    "\n",
    "Pero como consideramos que esta información es importante, hemos decidido trabajar la siguiente estrategia de imputación:\n",
    "\n",
    "- Reducir la cantidad de valores `0.00` por medio del `ID de cada trampa`. Como el ID de la trampa está en función del predio muestreado, es posible asumir que con que un ID de trampa contenga información del área, esta se puede replicar a las demás instancias de ese mismo ID de trampa en el tiempo.\n",
    "\n",
    "- Luego de esto, usaremos un algoritmo conocido como K-NN (K nearest neighbour) para verificar cuales trampas con un registro de superficie distinto a `0.00` se encuentran cerca de otras trampas con un área distinta a `0.00`. La distancia entre éstas trampas debe ser de un mínimo de 100m hasta 500m en época de jima según el manual de operación.\n",
    "\n",
    "- Después de usar K-NN, haremos uso también de `RadiusNeighborsRegressor`, el cual toma en cuenta la distancia entre los puntos para asumir si se encuentran cerca o no. \n",
    "\n",
    "- Por último, analizaremos cuántos registros quedan pendientes aún de tener un valor distinto a `0.00` y decidiremos más adelante qué hacer con ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8935499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trampas registradas con área mayor a 0.00: 428434\n",
      "Trampas registradas con área igual a 0.00: 399422\n"
     ]
    }
   ],
   "source": [
    "df = all_historic_captures_df\n",
    "\n",
    "print(f\"Trampas registradas con área mayor a 0.00: { (df['square_area'] > 0 ).sum()}\")\n",
    "print(f\"Trampas registradas con área igual a 0.00: { (df['square_area'] == 0 ).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d33e33",
   "metadata": {},
   "source": [
    "##### Usando el ID de trampa para llenar valores vacíos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ae5335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Delbert\\AppData\\Local\\Temp\\ipykernel_12132\\2819739940.py:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(get_nearest_temporal_area_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se llenaron 79287 registros usando el mismo ID de la trampa en el tiempo.\n"
     ]
    }
   ],
   "source": [
    "def get_nearest_temporal_area_group(group_to_verify):\n",
    "\n",
    "    # Casteamos datetime sobre sampling_date (fecha de muestreo)\n",
    "    group = group_to_verify.copy()\n",
    "    group['sampling_date_dt'] = pd.to_datetime(group['sampling_date'])\n",
    "    \n",
    "    # Tomamos solo las areas mayores a 0.00\n",
    "    areas_known = group.loc[group['square_area'] > 0.00, ['sampling_date_dt', 'square_area']]\n",
    "    if areas_known.empty:\n",
    "        return pd.Series(np.nan, index=group.index)\n",
    "    \n",
    "    # Calculamos la diferencia de tiempo en dias\n",
    "    diffs = np.abs(\n",
    "        group['sampling_date_dt'].values[:, None] - areas_known['sampling_date_dt'].values[None, :]\n",
    "    )\n",
    "    \n",
    "    # Tomamos la muestra con menor tiempo en comparación con la fecha que estamos revisando\n",
    "    idxmin = diffs.argmin(axis=1)\n",
    "    \n",
    "    return pd.Series(areas_known['square_area'].iloc[idxmin].values, index=group.index)\n",
    "\n",
    "\n",
    "# Generamos una copia de  la columna square_area\n",
    "df['square_area_imputed'] = df['square_area'].copy()\n",
    "\n",
    "# Generamos la columna de imputation_method: con lo siguiente:\n",
    "# Si el area es mayor a 0.00, entonces colocamos 'original'\n",
    "# Si el area es menor a 0.00, la marcamos para insertar valores\n",
    "df['imputation_method'] = np.where(df['square_area'] > 0, 'original', 'none')\n",
    "\n",
    "# Generamos una máscara para el dataframe\n",
    "mask = df['square_area'] == 0\n",
    "\n",
    "# Usamos la función para encontrar el area más próxima a cada tramp_id con area 0.00\n",
    "nearest_values = (\n",
    "    df.groupby('tramp_id', group_keys=False)\n",
    "      .apply(get_nearest_temporal_area_group)\n",
    ")\n",
    "\n",
    "# Insertamos los valores al dataframe original \n",
    "# Insertamos la forma en que se llenó la informacion del area\n",
    "df.loc[mask, 'square_area_imputed'] = nearest_values[mask]\n",
    "df.loc[mask & nearest_values.notna(), 'imputation_method'] = 'same_trap_id_temporal'\n",
    "\n",
    "rows_affected = df[ df['imputation_method'] == 'same_trap_id_temporal']\n",
    "print(f\"Se llenaron { len(rows_affected) } registros usando el mismo ID de la trampa en el tiempo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d31338",
   "metadata": {},
   "source": [
    "##### Ahora usaremos KNN para rellenar el resto de información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a643e0d",
   "metadata": {},
   "source": [
    "- `original`: son todas los registros de area que originalmente son distintos a 0.00\n",
    "- `none`: son los registros que aún no hemos imputado\n",
    "- `samte_trap_id_temporal`: son los registros que tienen un valor imputado en la columna `square_area_imputed` por medio de usar el `trap_id` y verificar la muestra más cercana en el tiempo que tenga area mayor a 0.00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867c2f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Origen de los valores de la columna square_area_imputed:\n",
      "imputation_method\n",
      "original                 428434\n",
      "none                     320135\n",
      "same_trap_id_temporal     79287\n",
      "Name: count, dtype: int64\n",
      "Registros a predecir su quare_area: 320,135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "import warnings\n",
    "\n",
    "print(\"\\nOrigen de los valores de la columna square_area_imputed:\")\n",
    "print(df['imputation_method'].value_counts())\n",
    "\n",
    "# Ignoraremos warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# No debemos  sobre-escribir lo que ya imputamos anterioremente\n",
    "# Entonces usaremos esos indexes como mascara\n",
    "train_mask = df['imputation_method'].isin(['original', 'same_trap_id_temporal'])\n",
    "\n",
    "# Tomamos los indexes que ya sabemos que en teoría están bien\n",
    "X_train = df[train_mask][['lat', 'lon']].values\n",
    "y_train = df[train_mask]['square_area_imputed'].values\n",
    "\n",
    "# Nuestro test serán los registros de los que sabemos que tienen 0.00 en square_area\n",
    "# y que no han sido imputados por el paso previo.\n",
    "test_mask = df['imputation_method'] == 'none'\n",
    "X_test = df[test_mask][['lat', 'lon']].values\n",
    "\n",
    "print(f\"Registros a predecir su quare_area: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eff01ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos Harversine para tomar en cuenta la curvatura de la tierra en la distancia que usemos para conocer cuales trampas están\n",
    "# cerca unas de otras, y se necesita que las longitudes y latitudes estén en radianes\n",
    "X_train_rad = np.radians(X_train)\n",
    "X_test_rad = np.radians(X_test)\n",
    "\n",
    "\n",
    "# Modelo 1: 4 trampas mas cercanas\n",
    "knn_1 = KNeighborsRegressor(\n",
    "    n_neighbors=4,\n",
    "    weights='distance',\n",
    "    metric='haversine',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "knn_1.fit(X_train_rad, y_train)\n",
    "predictions_1 = knn_1.predict(X_test_rad)\n",
    "\n",
    "# Modelo 2: 5 trampas mas cercanas\n",
    "knn_2 = KNeighborsRegressor(\n",
    "    n_neighbors=5,\n",
    "    weights='distance',\n",
    "    metric='haversine',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "knn_2.fit(X_train_rad, y_train)\n",
    "predictions_2 = knn_2.predict(X_test_rad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f709770",
   "metadata": {},
   "source": [
    "También entrenamos el modelo `RadiusNeighborsRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd18a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 3: las trampas contenidas en 500m a la redonda\n",
    "knn_3 = RadiusNeighborsRegressor(\n",
    "    radius = 0.250/6378, # 500 metros dentro de 6378 km del radio de la tierra\n",
    "    weights='distance',\n",
    "    metric='haversine' \n",
    ")\n",
    "\n",
    "knn_3.fit(X_train_rad, y_train)\n",
    "predictions_3 = knn_3.predict(X_test_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e9558fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Estadísticas para el modelo #1 sobre el area:\n",
      "======================================================================\n",
      "Promedio: 11.716221848897428\n",
      "Mediana: 5.933797917355816\n",
      "Desviacion estandar: 16.74506939865329\n",
      "Valor maximo: 294.428330125542\n",
      "Valor mínimo: 0.0384\n",
      "Cantidad de trampas sin área registrada: 0\n",
      "\n",
      "======================================================================\n",
      "Estadísticas para el modelo #2 sobre el area:\n",
      "======================================================================\n",
      "Promedio: 11.719764276551983\n",
      "Mediana: 5.999999999999999\n",
      "Desviacion estandar: 16.65718356129089\n",
      "Valor maximo: 289.0736297284621\n",
      "Valor mínimo: 0.041383444025189134\n",
      "Cantidad de trampas sin área registrada: 0\n",
      "\n",
      "======================================================================\n",
      "Estadísticas para el modelo #3 sobre el area:\n",
      "======================================================================\n",
      "Promedio: 9.640752701065155\n",
      "Mediana: 4.940517107486462\n",
      "Desviacion estandar: 13.89220421396947\n",
      "Valor maximo: 300.00000000000006\n",
      "Valor mínimo: 0.15000000000000002\n",
      "Cantidad de trampas sin área registrada: 57837\n",
      "\n",
      "======================================================================\n",
      "Estadísticas de los datos originales con area mayor a 0.00:\n",
      "======================================================================\n",
      "Promedio: 9.700518487656419\n",
      "Mediana: 3.7473\n",
      "Desviacion estandar: 18.117772785301234\n",
      "Valor maximo: 787.82\n",
      "Valor mínimo: 0.00469999993219971\n",
      "Cantidad de trampas sin área registrada: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_descriptive_stats_for_knn_model( title, preds ):\n",
    "    \n",
    "    print('='*70)\n",
    "    print(f\"{title}\")\n",
    "    print('='*70)\n",
    "    print(f\"Promedio: {np.nanmean(preds)}\")\n",
    "    print(f\"Mediana: {np.nanmedian(preds)}\")\n",
    "    print(f\"Desviacion estandar: {np.nanstd(preds)}\")\n",
    "    print(f\"Valor maximo: {np.nanmax(preds)}\")\n",
    "    print(f\"Valor mínimo: {np.nanmin(preds)}\")\n",
    "    print(f\"Cantidad de trampas sin área registrada: {np.isnan(preds).sum()}\\n\")\n",
    "\n",
    "print_descriptive_stats_for_knn_model('Estadísticas para el modelo #1 sobre el area:', predictions_1)\n",
    "print_descriptive_stats_for_knn_model('Estadísticas para el modelo #2 sobre el area:', predictions_2)\n",
    "print_descriptive_stats_for_knn_model('Estadísticas para el modelo #3 sobre el area:', predictions_3)\n",
    "\n",
    "already_imputed_mask = df['imputation_method'].isin(['original', 'same_trap_id_temporal'])\n",
    "print_descriptive_stats_for_knn_model('Estadísticas de los datos originales con area mayor a 0.00:', df[already_imputed_mask][df['square_area'] > 0.00000].square_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4cf13",
   "metadata": {},
   "source": [
    "#### Justificación sobre uso de modelos #2 y #3 en conjunto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa6763",
   "metadata": {},
   "source": [
    "**Colocar justificacion aquí**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff97da5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores NaN en square_area_imputed: 0\n",
      "Registros con método 'none': 0\n",
      "Todos los valores se han rellenado.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "imputation_method\n",
       "original                 428434\n",
       "knn_radius               262298\n",
       "same_trap_id_temporal     79287\n",
       "knn_5                     57837\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices = df[test_mask].index\n",
    "\n",
    "# Creamos otra máscara para insertar valores predecidos por los modelos #2 y #3\n",
    "# Como el modelo #3 es el que tiene las características descriptivas más parecidas a los valores originales,\n",
    "# usaremos ese de primero para insertar valores.\n",
    "model3_valid_mask = ~np.isnan(predictions_3)\n",
    "model3_nan_mask = np.isnan(predictions_3)\n",
    "\n",
    "df.loc[test_indices[model3_valid_mask], 'square_area_imputed'] = predictions_3[model3_valid_mask]\n",
    "df.loc[test_indices[model3_valid_mask], 'imputation_method'] = 'knn_radius'\n",
    "\n",
    "# Luego insertaremos las predicciones hechas con el modelo KNN con 4 vecinos\n",
    "df.loc[test_indices[model3_nan_mask], 'square_area_imputed'] = predictions_2[model3_nan_mask]\n",
    "df.loc[test_indices[model3_nan_mask], 'imputation_method'] = 'knn_5'\n",
    "\n",
    "# Imprimimos cuántos valores NaN o None nos quedan por rellenar aun\n",
    "remaining_nan = df['square_area_imputed'].isna().sum()\n",
    "remaining_none = (df['imputation_method'] == 'none').sum()\n",
    "\n",
    "print(f\"Valores NaN en square_area_imputed: {remaining_nan}\")\n",
    "print(f\"Registros con método 'none': {remaining_none}\")\n",
    "\n",
    "if remaining_nan == 0 and remaining_none == 0:\n",
    "    print(\"Todos los valores se han rellenado.\")\n",
    "else:\n",
    "    print(\"\\nSe deben rellenar aún más valores.\\n\\n\")\n",
    "    \n",
    "df['imputation_method'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7184207",
   "metadata": {},
   "source": [
    "### `Feature engineering` sobre `sampling_date`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c04c0",
   "metadata": {},
   "source": [
    "Primero obtendremos de nuevo las columnas de `Year` y `Year-Month` desde la fecha de muestreo. Estas variables son lineales, por lo tanto solo debemos normalizarlas o escalarlas.\n",
    "\n",
    "Respecto a `month`, `day_of_year`, `day_of_week` y `week_of_year` usaremos la representación trigonométrica (coseno y seno) para mantener las distancias entre mese, incluyendo el fin de año e inicio de año. Esto debido a que en el EDA fue bastante notorio que existe  un ciclo en la presencia del gorgojo de la siguiente manera:\n",
    "\n",
    "- De Enero a Mayo la cantidad de gorgojos encontrados fue menor que la cantidad de gorgojos muestreados de Junio a Diciembre.\n",
    "- Nuestro Sponsor considera que esto se debe a las lluvias, y  por lo tanto más adelante incluiremos la cantidad de mm de lluvia registrada por municipio y estado (esto con la ayuda del sitio oficial del gobierno de México)\n",
    "- Es necesario mantener la relación de Diciembre a Enero, y para esto se presta el uso de un encoding cíclico.\n",
    "- Al usar un encoding ciclico en los meses, días y semanas normalizamos la data en  un solo paso.\n",
    "- Una razón importante de implementar estos cambios es que todos se pueden obtener de la fecha de muestreo o reporte, por lo que al implementar el ChatBot esta información se podrá obtener solo con la fecha de reporte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbe9f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month']        = df['sampling_date'].dt.month\n",
    "df['year']         = df['sampling_date'].dt.year\n",
    "df['year_month']   = df['sampling_date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Hacemos el encoding trigonometrico para day_of_year (preserva la distancia de Diciembre a Enero tambien)\n",
    "df['day_of_year_sin'] = np.sin( 2 * np.pi * df['sampling_date'].dt.dayofyear / 365 )\n",
    "df['day_of_year_cos'] = np.cos( 2 * np.pi * df['sampling_date'].dt.dayofyear / 365 )\n",
    "\n",
    "# Es probable que el día de la semana funcione también, y es necesario preservar la distancia de domingo a lunes y viceversa\n",
    "df['day_of_week_sin'] = np.sin( 2 * np.pi * df['sampling_date'].dt.day_of_week / 7 )\n",
    "df['day_of_week_cos'] = np.cos( 2 * np.pi * df['sampling_date'].dt.day_of_week / 7 )\n",
    "\n",
    "# Trabajamos lo mismo con week_of_year\n",
    "df['week_of_year_sin'] = np.sin( (df['sampling_date'].dt.isocalendar().week/ 52 * 2 * np.pi) )\n",
    "df['week_of_year_cos'] = np.cos( (df['sampling_date'].dt.isocalendar().week/ 52 * 2 * np.pi) )\n",
    "\n",
    "# Encodeamos el mes tambien\n",
    "df['month_sin'] = np.sin( (df['sampling_date'].dt.month / 12 * 2 * np.pi) )\n",
    "df['month_cos'] = np.cos( (df['sampling_date'].dt.month / 12 * 2 * np.pi) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda451d0",
   "metadata": {},
   "source": [
    "El manual operativo de protección fitosanitaria menciona también que la época de lluvias se encuentra definida de Mayo a Septiembre, por lo que agregaremos una columna la cual tenga los siguientes valores:\n",
    "\n",
    "- `1` para la temporada de lluvias definida en el manual operativo.\n",
    "- `0` para la temporada que no se considera como de lluvia en el manual operativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de846e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_months = [ 5, 6, 7, 8, 9 ]\n",
    "\n",
    "#  Usamos list comprehension\n",
    "df['critical_season'] = [1 if m in critical_months else 0 for m in df['month'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c63b8",
   "metadata": {},
   "source": [
    "Es posible crear la siguiente columna: `days_since_last_capture`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d373e8",
   "metadata": {},
   "source": [
    "### `Feature engineering` para características espaciales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a43fb",
   "metadata": {},
   "source": [
    "Es importante conocer la densidad de la presencia de trampas para que nuestro ChatBot pueda responder si la ubicación enviada se encuentra cerca de alguno de los puntos de infección recientes, y dar un mejor contexto a los usuarios.\n",
    "\n",
    "Para esto, hemos decidido crear los siguientes features:\n",
    "\n",
    "- `distance_to_nearest_hotspot`\n",
    "- `hotspots_within_5km`\n",
    "- `hotspots_within_10km`\n",
    "\n",
    "Y para definir un hotspot tenemos la siguiente opción:\n",
    "\n",
    "- Usar la actual escala `severity` de nuestro dataset y hacer encoding sobre ésta, ya que según el manual operativo se cuenta con 4 niveles de infestación:\n",
    "    - `Primer nivel`: se presenta cuando en las trampas no hay presencia de gorgojos.\n",
    "    - `Segundo nivel`: se da cuando en las trampas se halla presencia de entre 1 a 24 gorgojos.\n",
    "    - `Tercer nivel`: se considera cuando en una trampa se encuentran 25 a 75 gorgojos.\n",
    "    - `Cuarto nivel`: se presenta cuando en las trampas se encuentran más de 75 gorgojos. Esto se considera como un foco de infestación, porque representa una media de 5 gorgojos muestreados por día en 15 días.\n",
    "\n",
    "Entonces el primer paso es hacer encoding sobre estos niveles, los cuales son una variable ordinal (ya que se presenta una escala de mejor a peor escenario), y debemos codificarlos de manera que el LLM a implementar pueda relacionar el nivel de riesgo que cada foco implica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa46c20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nivel original de severidad:\n",
      "\n",
      "severity\n",
      "1-25     518659\n",
      "0        291465\n",
      "25-75     16476\n",
      ">75        1256\n",
      "Name: count, dtype: int64\n",
      "======================================================================\n",
      "Nivel codificado de severidad:\n",
      "\n",
      "severity_encoded\n",
      "Con riesgo leve                       518659\n",
      "Sin riesgo                            291465\n",
      "Con riesgo moderado                    16476\n",
      "Riesgo severo, foco de infestacion      1256\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nivel original de severidad:\\n\\n{df['severity'].value_counts()}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "severity_mapping = {\n",
    "     '0'    : 'Sin riesgo',\n",
    "     '1-25' : 'Con riesgo leve',\n",
    "     '25-75': 'Con riesgo moderado',\n",
    "     '>75'  : 'Riesgo severo, foco de infestacion'\n",
    "}\n",
    "\n",
    "df['severity_encoded'] = df['severity'].map(severity_mapping)\n",
    "print( f\"Nivel codificado de severidad:\\n\\n{df['severity_encoded'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8fe576",
   "metadata": {},
   "source": [
    "Y ahora que ya tenemos definido el nivel de riesgo por cada trampa muestreada, es posible  iniciar a definir las variables `distance_to_nearest_hotspot`, `hotspots_between_5km` y `hotspots_between_10km` respectivamente, ya que éstas le darán más contexto al LLM. Y para reducir la ventana de búsqueda, haremos uso de una venta de tiempo de 15 días."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e08fc6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "# Funcion para usar la distancia usando la formula de Harversine\n",
    "\n",
    "def distance_between_traps(lat1, lon1, lat2, lon2):\n",
    "    # Radio de la tierra\n",
    "    r = 6371.0\n",
    "    \n",
    "    # Volvemos radianos las ubicaciones\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Diferencia entre latitudes y longitudes en radianes\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    # Formular de Harversine\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    distance = r * 2 * np.arcsin(np.sqrt(a))\n",
    "    # Resultado\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e696e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para tomar en  cuenta la cantidad de hotspots a 5km y 10km que estuvieron presentes durante los 15 días previos y posteriores a la muestra\n",
    "# si se requiere, se pueden cambiar los dias previos y posteriores a analizar por fecha de muestreo.\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def proximity_to_hotspots(df, days_before=15, days_after=15):\n",
    "    \n",
    "    df = df.sort_values(\"sampling_date\").reset_index(drop=True)\n",
    "    df[\"sampling_date\"] = pd.to_datetime(df[\"sampling_date\"])\n",
    "\n",
    "    hotspots = df[df[\"is_hotspot\"]][[\"sampling_date\", \"lat\", \"lon\"]].copy()\n",
    "    hotspots[\"sampling_date\"] = pd.to_datetime(hotspots[\"sampling_date\"])\n",
    "\n",
    "    # Inicializamos las salidas (se crean las nuevas columnas)\n",
    "    df[\"distance_to_nearest_hotspot\"] = np.inf\n",
    "    df[\"hotspots_within_5km\"] = 0\n",
    "    df[\"hotspots_within_10km\"] = 0\n",
    "\n",
    "    # Usaremos fechas unicas para procesar de a poco cada valor\n",
    "    unique_dates = df[\"sampling_date\"].sort_values().unique()\n",
    "\n",
    "    # Iniciamos el ciclo por fecha unica\n",
    "    for current_date in unique_dates:\n",
    "        \n",
    "        # Fecha minima y maxima a calcular por cada trampa\n",
    "        date_min = current_date - timedelta(days=days_before)\n",
    "        date_max = current_date + timedelta(days=days_after)\n",
    "\n",
    "        # Tomamos las trampas por fecha unica\n",
    "        df_subset = df[df[\"sampling_date\"] == current_date]\n",
    "        \n",
    "        # buscamos los hotspots en los 15 dias previos y posteriores\n",
    "        hot_subset = hotspots[\n",
    "            (hotspots[\"sampling_date\"] >= date_min) & \n",
    "            (hotspots[\"sampling_date\"] <= date_max)\n",
    "        ]\n",
    "\n",
    "        if len(hot_subset) == 0 or len(df_subset) == 0:\n",
    "            continue\n",
    "\n",
    "        # Armamos un arbol KDT\n",
    "        tree = cKDTree(np.radians(hot_subset[[\"lat\", \"lon\"]].values))\n",
    "\n",
    "        # \n",
    "        trap_coords = np.radians(df_subset[[\"lat\", \"lon\"]].values)\n",
    "\n",
    "        \n",
    "        try:\n",
    "            # Para Scipy 1.9 o superior\n",
    "            dists, _ = tree.query(trap_coords, k=1, workers=-1)\n",
    "        except TypeError:\n",
    "            # Para versiones antiguas de SciPy (como la nuestra)\n",
    "            dists, _ = tree.query(trap_coords, k=1)\n",
    "\n",
    "        dists_km = dists * 6371  # convert radians to km\n",
    "\n",
    "        \n",
    "        count_5km = tree.query_ball_point(trap_coords, r=5/6371, workers=-1)\n",
    "        count_10km = tree.query_ball_point(trap_coords, r=10/6371, workers=-1)\n",
    "\n",
    "        idx = df_subset.index\n",
    "        df.loc[idx, \"distance_to_nearest_hotspot\"] = dists_km\n",
    "        df.loc[idx, \"hotspots_within_5km\"] = [len(c) for c in count_5km]\n",
    "        df.loc[idx, \"hotspots_within_10km\"] = [len(c) for c in count_10km]\n",
    "\n",
    "    return df\n",
    "\n",
    "severe_risk_capture_threshold = 75\n",
    "\n",
    "df['is_hotspot'] = (\n",
    "    (df['capture_count'] > severe_risk_capture_threshold) | (df['severity_encoded'] == 'Riesgo severo, foco de infestacion' )\n",
    ")\n",
    "\n",
    "df = proximity_to_hotspots(df) # Obtendremos la cantidad de hotspots cercanos, a 5km y 10km en los 15 dias previos y futuros por defecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebc2006",
   "metadata": {},
   "source": [
    "### ¿`Feature engineering` sobre `Estado` y `Municipalidad`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e9e216",
   "metadata": {},
   "source": [
    "Antes de analizar estas columnas, debemos corregir 2 aspectos que se encuentran presentes en el Dataset:\n",
    "\n",
    "- Cambiar `Michoacan de Ocampo` por `Michoacan`.\n",
    "- Cambiar el estado de `Ixtlan del Rio` a `Nayarit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4f90e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Primero corregimos Michoacan de Ocampo para que forme parte de la categoría 'Michoacan'\n",
    "df['state'].replace('MICHOACÁN DE OCAMPO', 'MICHOACAN', inplace=True)\n",
    "\n",
    "# Corregimos las instancias de Ixtlan del \n",
    "df.loc[df['municipality'] == 'IXTLÁN DEL RÍO', 'state'] = 'NAYARIT'\n",
    "\n",
    "# Aprovechamos a eliminar tildes\n",
    "\n",
    "def remove_accents(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    return ''.join(c for c in unicodedata.normalize('NFKD', str(text)) if not unicodedata.combining(c))\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    text = remove_accents(text)\n",
    "    return re.sub(r'[^A-Za-z0-9\\s]', '', text).upper()\n",
    "\n",
    "state_municipality_cols = ['state', 'municipality']\n",
    "\n",
    "for col in state_municipality_cols:\n",
    "    df[col] = df[col].apply(remove_accents)\n",
    "    \n",
    "for col in state_municipality_cols:\n",
    "    df[col] = df[col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5518bb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos para State: 5\n",
      "Valores únicos para Municipality: 149\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valores únicos para State: {df['state'].nunique()}\")\n",
    "print(f\"Valores únicos para Municipality: {df['municipality'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e2f2f7",
   "metadata": {},
   "source": [
    "Luego de esto, hemos decidido no llevar a cabo algún encoding para estas columnas por los siguientes motivos:\n",
    "\n",
    "- El LLM que se utilice para desarrollar el ChatBot puede hacer uso de estos textos para dar respuestas descriptivas. No es lo mismo alimentar al ChatBot haciendo uso de valores como `1`, `2` o `3` que `Jalisco`, `Nayarit` y `Michoacan`, por ejemplo.\n",
    "- La investigación de Koloski *et al.* indica que el uso de text embeddings para LLMs ayuda a que el LLM tenga un mejor resultado acorde a lo que se le cuestione. Por lo tanto, tendremos que convertir nuestra data tabular a embeddings para lograr que nuestro ChatBot responda de mejor manera usando el contexto  que nuestro dataset le dé.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Referencias:\n",
    "- https://realpython.com/build-llm-rag-chatbot-with-langchain/#explore-the-available-data\n",
    "- https://arxiv.org/abs/2502.11596"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a391d",
   "metadata": {},
   "source": [
    "### `Feature engineering` para `Text Embeddings`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d57f6a",
   "metadata": {},
   "source": [
    "Ahora que hemos obtenida varias columnas o features más (16 aproximadamente), es posible crear las siguientes columnas:\n",
    "\n",
    "- `location_description`, la cual puede incluir un texto que mencione el municipio, estado y ubicacion (lat y lon).\n",
    "- `risk_summ`, lo cual puede incluir el riesgo o  severidad, la cantidad de capturas y hostspots cercanos por cada punto.\n",
    "- `temporal_description` que incluiría la fecha, severidad, si se encuentra en una temporada crítica o no, etc.\n",
    "\n",
    "Estos textos ayudarán a llevar a cabo el fine-tuning del modelo LLM que seleccionemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location_summary'] = f\"Trampa {df['tramp_id']} se encuentra ubicada en la latitud {df['lat']} y longitud {df['lon']}, en la jurisdicción de la municipalidad de {df['municipality']}, estado {df['state']}\"\n",
    "df['risk_summary'] = f\"Trampa {df['tramp_id']} {df['severity_encoded']} con {df['capture_count']} capturas registradas el {df['sampling_date']} con {df['distance_to_nearest_hotspot']} km de distancia del foco de infestacion mas cercano\"\n",
    "df['hotspots_near'] = f\"Trampa {df['tramp_id']} tiene {df['']}\"\n",
    "df['temporal_description'] = f\"Trampa {df['tramp_id']} revisada {df['sampling_date']} \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29ba6e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['original', 'knn_radius', 'knn_5', 'same_trap_id_temporal'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['imputation_method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "418c1f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tramp_id', 'sampling_date', 'lat', 'lon', 'municipality',\n",
       "       'square_area', 'plantation_age', 'capture_count', 'state', 'severity',\n",
       "       'square_area_imputed', 'imputation_method', 'month', 'year',\n",
       "       'year_month', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week_sin',\n",
       "       'day_of_week_cos', 'week_of_year_sin', 'week_of_year_cos', 'month_sin',\n",
       "       'month_cos', 'critical_season', 'severity_encoded', 'is_hotspot',\n",
       "       'distance_to_nearest_hotspot', 'hotspots_within_5km',\n",
       "       'hotspots_within_10km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0fbd4",
   "metadata": {},
   "source": [
    "# Conlusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d387e1",
   "metadata": {},
   "source": [
    "#### Sobre `imputation_method`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bd8e86",
   "metadata": {},
   "source": [
    "#### Sobre los `features temporales`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70bfac",
   "metadata": {},
   "source": [
    "#### Sobre las `características espaciales`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692b3bd",
   "metadata": {},
   "source": [
    "#### Sobre `Estado` y `Municipalidad`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
