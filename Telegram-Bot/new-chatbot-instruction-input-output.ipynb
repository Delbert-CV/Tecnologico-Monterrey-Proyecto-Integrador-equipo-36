{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "762d4a43",
   "metadata": {},
   "source": [
    "# Librerías a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87989b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python_Envs\\torch311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Python_Envs\\torch311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import Field\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from typing import Optional, List, Any\n",
    "from langchain.schema import Document\n",
    "from transformers import pipeline\n",
    "from peft import PeftModel\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import gc\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da900b91",
   "metadata": {},
   "source": [
    "# Generacion de archivos para alimentar el sistema RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6775fb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tramp_id', 'sampling_date', 'lat', 'lon', 'municipality',\n",
       "       'square_area', 'plantation_age', 'capture_count', 'state',\n",
       "       'square_area_imputed', 'month', 'year', 'year_month', 'day_of_year_sin',\n",
       "       'day_of_year_cos', 'day_of_week_sin', 'day_of_week_cos',\n",
       "       'week_of_year_sin', 'week_of_year_cos', 'month_sin', 'month_cos',\n",
       "       'critical_season', 'severity_encoded', 'distance_to_nearest_hotspot',\n",
       "       'hotspots_within_5km', 'text_feature_location', 'text_feature_risk',\n",
       "       'text_feature_capture', 'text_feature_plantation',\n",
       "       'text_feature_all_things'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('baseline.xlsx')\n",
    "df.drop(labels=['Unnamed: 0'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a591f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d890768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "827856"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_backup\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a75b8163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tramp_id                               object\n",
       "sampling_date                  datetime64[ns]\n",
       "lat                                   float64\n",
       "lon                                   float64\n",
       "municipality                           object\n",
       "square_area                           float64\n",
       "plantation_age                          int64\n",
       "capture_count                         float64\n",
       "state                                  object\n",
       "square_area_imputed                   float64\n",
       "month                                   int64\n",
       "year                                    int64\n",
       "year_month                             object\n",
       "day_of_year_sin                       float64\n",
       "day_of_year_cos                       float64\n",
       "day_of_week_sin                       float64\n",
       "day_of_week_cos                       float64\n",
       "week_of_year_sin                      float64\n",
       "week_of_year_cos                      float64\n",
       "month_sin                             float64\n",
       "month_cos                             float64\n",
       "critical_season                         int64\n",
       "severity_encoded                        int64\n",
       "distance_to_nearest_hotspot           float64\n",
       "hotspots_within_5km                     int64\n",
       "text_feature_location                  object\n",
       "text_feature_risk                      object\n",
       "text_feature_capture                   object\n",
       "text_feature_plantation                object\n",
       "text_feature_all_things                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c335da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158408"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_mask = df['year'] >= 2024\n",
    "month_mask = df['month'] >= 1\n",
    "df = df[year_mask]\n",
    "df = df[month_mask] \n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_dict = {\n",
    "    0: 'sin riesgo',\n",
    "    1: 'de riesgo leve',\n",
    "    2: 'de riesgo moderado',\n",
    "    3: 'de riesgo severo'\n",
    "}\n",
    "\n",
    "critical_season_dict = {\n",
    "    0: 'normal',\n",
    "    1: 'critica'\n",
    "}\n",
    "\n",
    "\n",
    "area_information_dict = {\n",
    "    'original': \" (area historica registrada correctamente)\", \n",
    "    'radius_regressor' : \"(el area en hectareas se calculo usando trampas cercanas)\", \n",
    "    'median' : \"(el area en hectareas se calculo usando la mediana de los datos de muestra)\", \n",
    "    'same_trap_id_temporal' : \" (valor del area en hectarea obtenido usando registros historicos)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9635cc",
   "metadata": {},
   "source": [
    "### Generación de archivos para fine-tuning de Phi3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rich_input(x):\n",
    "    return (\n",
    "        f\"tramp_id: {x['tramp_id']}, \"\n",
    "        f\"sampling_date: {x['sampling_date'].strftime('%d-%m-%Y')}, \"\n",
    "        f\"lat: {x['lat']}, lon: {x['lon']}, \"\n",
    "        f\"municipality: {x['municipality']}, state: {x['state']}, \"\n",
    "        f\"capture_count: {x['capture_count']}, severity: {x['severity_encoded']}, \"\n",
    "        f\"critical_season: {x['critical_season']}, \"\n",
    "        f\"hotspots_within_5km: {x['hotspots_within_5km']}, \"\n",
    "        f\"distance_to_nearest_hotspot: {x['distance_to_nearest_hotspot']}, \"\n",
    "        f\"plantation_age: {x['plantation_age']}, \"\n",
    "        f\"square_area_imputed: {x['square_area_imputed']}, \"\n",
    "        f\"month: {x['month']}, year_month: {x['year_month']}, \"\n",
    "        f\"day_of_year_sin: {x['day_of_year_sin']}, day_of_year_cos: {x['day_of_year_cos']}, \"\n",
    "        f\"week_of_year_sin: {x['week_of_year_sin']}, week_of_year_cos: {x['week_of_year_cos']}, \"\n",
    "    )\n",
    "\n",
    "df[\"input_rich\"] = df.apply(build_rich_input, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_risk_temporal(x):\n",
    "    cc = x['capture_count']\n",
    "    cs = x['critical_season']\n",
    "    sev = x['severity_encoded']\n",
    "\n",
    "    if cc > 15 and cs == 1:\n",
    "        return \"El conteo de capturas es alto durante temporada crítica. Esto sugiere un riesgo elevado consistente con los patrones estacionales recientes.\"\n",
    "    elif cc > 0 and cs == 1:\n",
    "        return \"Hay capturas moderadas en temporada crítica. El comportamiento es esperado, sin indicios de anomalía fuerte.\"\n",
    "    elif sev >= 2:\n",
    "        return \"Aunque no es temporada crítica, la severidad es moderada. Conviene mantener vigilancia.\"\n",
    "    else:\n",
    "        return \"El nivel de captura es bajo y fuera de temporada crítica. Riesgo estable sin cambios relevantes.\"\n",
    "    \n",
    "def generate_output_geospatial(x):\n",
    "    h5 = x['hotspots_within_5km']\n",
    "    dist = x['distance_to_nearest_hotspot']\n",
    "    sev = x['severity_encoded']\n",
    "\n",
    "    if h5 >= 3 and dist < 1500:\n",
    "        return \"La trampa se ubica cerca de varios hotspots activos. La presión fitosanitaria es alta y el riesgo es creciente.\"\n",
    "    elif h5 >= 1 and dist < 3000:\n",
    "        return \"Hay hotspots cercanos con distancia moderada. Existe riesgo medio que requiere seguimiento.\"\n",
    "    elif sev >= 2:\n",
    "        return \"Sin hotspots cercanos, pero la severidad es moderada. Riesgo localizado que debe vigilarse.\"\n",
    "    else:\n",
    "        return \"Sin hotspots significativos y severidad baja. Riesgo estable en la zona.\"\n",
    "\n",
    "\n",
    "def generate_output_vulnerability(x):\n",
    "    age = x['plantation_age']\n",
    "    area = x['square_area_imputed']\n",
    "    cc = x['capture_count']\n",
    "\n",
    "    if age >= 5 and cc > 10:\n",
    "        return \"La plantación madura presenta capturas elevadas. Existe vulnerabilidad alta a infestación.\"\n",
    "    elif age >= 3 and cc > 0:\n",
    "        return \"Plantación de edad media con capturas moderadas. Riesgo potencial que debe monitorearse.\"\n",
    "    elif area > 5 and cc > 0:\n",
    "        return \"Predio de gran superficie con presencia de capturas. El tamaño puede facilitar propagación, riesgo medio.\"\n",
    "    else:\n",
    "        return \"La combinación de edad, superficie y capturas no sugiere vulnerabilidad relevante.\"\n",
    "\n",
    "\n",
    "def generate_output_weekly_anomaly(x):\n",
    "    cc = x['capture_count']\n",
    "    sev = x['severity_encoded']\n",
    "    week_sin = x['week_of_year_sin']\n",
    "    week_cos = x['week_of_year_cos']\n",
    "\n",
    "    week_mag = (week_sin**2 + week_cos**2)**0.5\n",
    "\n",
    "    if cc > 20 and week_mag > 0.9:\n",
    "        return \"La actividad de capturas es mayor al patrón típico de la semana. Posible anomalía detectada.\"\n",
    "    elif cc > 5:\n",
    "        return \"Las capturas son moderadas para esta semana. El comportamiento es cercano al patrón esperado.\"\n",
    "    else:\n",
    "        return \"Actividad baja y dentro del rango esperado para la semana.\"\n",
    "\n",
    "\n",
    "def generate_output_municipal_risk(x):\n",
    "    h5 = x['hotspots_within_5km']\n",
    "    cc = x['capture_count']\n",
    "    sev = x['severity_encoded']\n",
    "    muni = x['municipality']\n",
    "\n",
    "    if h5 >= 3 and cc > 10:\n",
    "        return f\"En {muni}, los datos recientes muestran capturas altas y varios hotspots cercanos. El riesgo municipal es elevado.\"\n",
    "    elif h5 >= 1 and cc > 5:\n",
    "        return f\"En {muni}, hay presión moderada por hotspots y capturas. Riesgo municipal medio.\"\n",
    "    elif sev >= 2:\n",
    "        return f\"En {muni}, la severidad local es moderada pese a baja actividad geográfica. Riesgo localizado.\"\n",
    "    else:\n",
    "        return f\"En {muni}, el comportamiento reciente es estable. No hay señales de riesgo destacado.\"\n",
    "\n",
    "\n",
    "df[\"output_risk_temporal\"] = df.apply(generate_output_risk_temporal, axis=1)\n",
    "df[\"output_geospatial\"] = df.apply(generate_output_geospatial, axis=1)\n",
    "df[\"output_vulnerability\"] = df.apply(generate_output_vulnerability, axis=1)\n",
    "df[\"output_weekly_anomaly\"] = df.apply(generate_output_weekly_anomaly, axis=1)\n",
    "df[\"output_municipal_risk\"] = df.apply(generate_output_municipal_risk, axis=1)\n",
    "\n",
    "instructions_temporal = [\n",
    "    \"Evalúa el riesgo fitosanitario usando temporada crítica, capturas y estacionalidad. Usa solo datos de julio 2025 en adelante.\",\n",
    "    \"Determina si el comportamiento temporal del gorgojo es normal o anómalo usando month y critical_season.\"\n",
    "]\n",
    "\n",
    "instructions_geospatial = [\n",
    "    \"Evalúa el riesgo usando hotspots cercanos, distancia y severidad. Habla solo basado en datos posteriores a julio 2025.\",\n",
    "    \"Determina si hay presión fitosanitaria cercana según hotspots_within_5km y distancia al hotspot.\"\n",
    "]\n",
    "\n",
    "instructions_vulnerability = [\n",
    "    \"Evalúa la vulnerabilidad combinando edad de plantación, superficie y capturas usando datos posteriores a julio 2025.\",\n",
    "    \"Determina si la plantación es propensa a infestación según plantation_age, area y capturas.\"\n",
    "]\n",
    "\n",
    "instructions_weekly = [\n",
    "    \"Determina si existe anomalía semanal usando capture_count y las variables week_of_year_sin/cos desde julio 2025.\",\n",
    "    \"Compara la actividad semanal con el patrón esperado para identificar anomalías.\"\n",
    "]\n",
    "\n",
    "instructions_municipal = [\n",
    "    \"Resume el riesgo municipal usando capturas recientes, hotspots y year_month solo con datos desde julio 2025.\",\n",
    "    \"Evalúa si el municipio muestra tendencia de riesgo según capturas y hotspots cercanos.\"\n",
    "]\n",
    "\n",
    "def generate_jsonl(path, df, instruction_list, output_col):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            for inst in instruction_list:\n",
    "                record = {\n",
    "                    \"instruction\": inst,\n",
    "                    \"input\": row[\"input_rich\"],\n",
    "                    \"output\": row[output_col]\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"✅ JSONL generado: {path}\")\n",
    "    \n",
    "    \n",
    "generate_jsonl(\"agave_risk_temporal.jsonl\", df, instructions_temporal, \"output_risk_temporal\")\n",
    "generate_jsonl(\"agave_geospatial.jsonl\", df, instructions_geospatial, \"output_geospatial\")\n",
    "generate_jsonl(\"agave_vulnerability.jsonl\", df, instructions_vulnerability, \"output_vulnerability\")\n",
    "generate_jsonl(\"agave_weekly_anomaly.jsonl\", df, instructions_weekly, \"output_weekly_anomaly\")\n",
    "generate_jsonl(\"agave_municipal_risk.jsonl\", df, instructions_municipal, \"output_municipal_risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbbb993",
   "metadata": {},
   "source": [
    "# Generación de archivos para generar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a010e722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando agregaciones por Estado...\n",
      "Procesando agregaciones por Municipio...\n",
      "Procesando agregaciones por Mes...\n",
      "Procesando agregaciones por Estado + Mes...\n",
      "Procesando agregaciones por Municipio + Mes...\n",
      "\n",
      "Guardando 1553 registros en historic_data.jsonl...\n",
      "✓ Archivo JSONL para RAG generado exitosamente: historic_data.jsonl\n",
      "\n",
      "Resumen de registros generados:\n",
      "  - Por estado: 4 registros\n",
      "  - Por municipio: 143 registros\n",
      "  - Por mes: 12 registros\n",
      "  - Por estado + mes: 48 registros\n",
      "  - Por municipio + mes: 1346 registros\n",
      "  - TOTAL: 1553 registros\n",
      "\n",
      "================================================================================\n",
      "EJEMPLOS DE DESCRIPCIONES EN LENGUAJE NATURAL:\n",
      "================================================================================\n",
      "\n",
      "STATE:\n",
      "--------------------------------------------------------------------------------\n",
      "TEXTO: En el período de 2024-2025, en el estado de GUANAJUATO, se registró un promedio de 4.05 gorgojos picudos capturados por trampa. La mediana de capturas fue de 3.00, con un rango intercuartílico entre 1.00 (percentil 25) y 5.00 (percentil 75). La desviación estándar de las capturas fue de 4.70, lo que indica una alta variabilidad en las capturas. Estos datos se basan en 5020 observaciones registradas. La edad promedio de las plantaciones de agave en esta área fue de 3.93 años. Este promedio de capturas sugiere un bajo nivel de infestación del picudo del agave en la zona.\n",
      "\n",
      "METADATA: {\n",
      "  \"aggregation_level\": \"state\",\n",
      "  \"state\": \"GUANAJUATO\",\n",
      "  \"municipality\": null,\n",
      "  \"month\": null,\n",
      "  \"year_range\": \"2024-2025\",\n",
      "  \"avg_captures\": 4.05,\n",
      "  \"observation_count\": 5020\n",
      "}\n",
      "\n",
      "MUNICIPALITY:\n",
      "--------------------------------------------------------------------------------\n",
      "TEXTO: En el período de 2024-2025, en el municipio de ABASOLO, GUANAJUATO, se registró un promedio de 3.41 gorgojos picudos capturados por trampa. La mediana de capturas fue de 3.00, con un rango intercuartílico entre 1.00 (percentil 25) y 5.00 (percentil 75). La desviación estándar de las capturas fue de 3.22, lo que indica una variabilidad moderada en las capturas. Estos datos se basan en 459 observaciones registradas. La edad promedio de las plantaciones de agave en esta área fue de 3.67 años. Este promedio de capturas sugiere un bajo nivel de infestación del picudo del agave en la zona.\n",
      "\n",
      "METADATA: {\n",
      "  \"aggregation_level\": \"municipality\",\n",
      "  \"state\": \"GUANAJUATO\",\n",
      "  \"municipality\": \"ABASOLO\",\n",
      "  \"month\": null,\n",
      "  \"year_range\": \"2024-2025\",\n",
      "  \"avg_captures\": 3.41,\n",
      "  \"observation_count\": 459\n",
      "}\n",
      "\n",
      "MONTH:\n",
      "--------------------------------------------------------------------------------\n",
      "TEXTO: En el período de 2024-2025, a nivel nacional durante el mes de January, se registró un promedio de 5.22 gorgojos picudos capturados por trampa. La mediana de capturas fue de 3.00, con un rango intercuartílico entre 1.00 (percentil 25) y 6.00 (percentil 75). La desviación estándar de las capturas fue de 8.10, lo que indica una alta variabilidad en las capturas. Estos datos se basan en 12463 observaciones registradas. La edad promedio de las plantaciones de agave en esta área fue de 3.50 años. Este promedio de capturas sugiere un nivel moderado de infestación del picudo del agave en la zona.\n",
      "\n",
      "METADATA: {\n",
      "  \"aggregation_level\": \"month\",\n",
      "  \"state\": null,\n",
      "  \"municipality\": null,\n",
      "  \"month\": \"January\",\n",
      "  \"year_range\": \"2024-2025\",\n",
      "  \"avg_captures\": 5.22,\n",
      "  \"observation_count\": 12463\n",
      "}\n",
      "\n",
      "STATE MONTH:\n",
      "--------------------------------------------------------------------------------\n",
      "TEXTO: En el período de 2024-2025, en el estado de GUANAJUATO durante el mes de January, se registró un promedio de 5.50 gorgojos picudos capturados por trampa. La mediana de capturas fue de 4.00, con un rango intercuartílico entre 2.00 (percentil 25) y 7.00 (percentil 75). La desviación estándar de las capturas fue de 5.89, lo que indica una alta variabilidad en las capturas. Estos datos se basan en 425 observaciones registradas. La edad promedio de las plantaciones de agave en esta área fue de 4.05 años. Este promedio de capturas sugiere un nivel moderado de infestación del picudo del agave en la zona.\n",
      "\n",
      "METADATA: {\n",
      "  \"aggregation_level\": \"state_month\",\n",
      "  \"state\": \"GUANAJUATO\",\n",
      "  \"municipality\": null,\n",
      "  \"month\": \"January\",\n",
      "  \"year_range\": \"2024-2025\",\n",
      "  \"avg_captures\": 5.5,\n",
      "  \"observation_count\": 425\n",
      "}\n",
      "\n",
      "MUNICIPALITY MONTH:\n",
      "--------------------------------------------------------------------------------\n",
      "TEXTO: En el período de 2025-2025, en el municipio de ABASOLO, GUANAJUATO, durante el mes de January, se registró un promedio de 4.43 gorgojos picudos capturados por trampa. La mediana de capturas fue de 4.00, con un rango intercuartílico entre 2.00 (percentil 25) y 5.00 (percentil 75). La desviación estándar de las capturas fue de 3.07, lo que indica una variabilidad moderada en las capturas. Estos datos se basan en 25 observaciones registradas. La edad promedio de las plantaciones de agave en esta área fue de 4.64 años. Este promedio de capturas sugiere un bajo nivel de infestación del picudo del agave en la zona.\n",
      "\n",
      "METADATA: {\n",
      "  \"aggregation_level\": \"municipality_month\",\n",
      "  \"state\": \"GUANAJUATO\",\n",
      "  \"municipality\": \"ABASOLO\",\n",
      "  \"month\": \"January\",\n",
      "  \"year_range\": \"2025-2025\",\n",
      "  \"avg_captures\": 4.43,\n",
      "  \"observation_count\": 25\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_natural_language_description(record):\n",
    "    \n",
    "    agg_level = record['aggregation_level']\n",
    "    \n",
    "    # Construir la descripción según el nivel de agregación\n",
    "    if agg_level == 'state':\n",
    "        location = f\"en el estado de {record['state']}\"\n",
    "        \n",
    "    elif agg_level == 'municipality':\n",
    "        location = f\"en el municipio de {record['municipality']}, {record['state']}\"\n",
    "        \n",
    "    elif agg_level == 'month':\n",
    "        location = f\"a nivel nacional durante el mes de {record['month']}\"\n",
    "        \n",
    "    elif agg_level == 'state_month':\n",
    "        location = f\"en el estado de {record['state']} durante el mes de {record['month']}\"\n",
    "        \n",
    "    elif agg_level == 'municipality_month':\n",
    "        location = f\"en el municipio de {record['municipality']}, {record['state']}, durante el mes de {record['month']}\"\n",
    "    \n",
    "    # Construcción de la descripción en lenguaje natural\n",
    "    description_parts = []\n",
    "    \n",
    "    # Introducción con contexto geográfico/temporal\n",
    "    intro = f\"En el período de {record['year_range']}, {location},\"\n",
    "    description_parts.append(intro)\n",
    "    \n",
    "    # Estadísticas de captura\n",
    "    capture_desc = (\n",
    "        f\"se registró un promedio de {record['avg_captures']:.2f} gorgojos picudos capturados por trampa. \"\n",
    "        f\"La mediana de capturas fue de {record['median_captures']:.2f}, \"\n",
    "        f\"con un rango intercuartílico entre {record['p25_captures']:.2f} (percentil 25) \"\n",
    "        f\"y {record['p75_captures']:.2f} (percentil 75).\"\n",
    "    )\n",
    "    description_parts.append(capture_desc)\n",
    "    \n",
    "    # Variabilidad\n",
    "    if record['std_captures'] is not None:\n",
    "        variability_desc = f\"La desviación estándar de las capturas fue de {record['std_captures']:.2f}, \"\n",
    "        \n",
    "        # Interpretar la variabilidad\n",
    "        cv = (record['std_captures'] / record['avg_captures']) * 100 if record['avg_captures'] > 0 else 0\n",
    "        if cv < 50:\n",
    "            variability_desc += \"lo que indica una variabilidad relativamente baja en las capturas.\"\n",
    "        elif cv < 100:\n",
    "            variability_desc += \"lo que indica una variabilidad moderada en las capturas.\"\n",
    "        else:\n",
    "            variability_desc += \"lo que indica una alta variabilidad en las capturas.\"\n",
    "        \n",
    "        description_parts.append(variability_desc)\n",
    "    \n",
    "    # Información de muestreo\n",
    "    sample_desc = f\"Estos datos se basan en {record['observation_count']} observaciones registradas.\"\n",
    "    description_parts.append(sample_desc)\n",
    "    \n",
    "    # Edad de plantación\n",
    "    if record['avg_plantation_age'] is not None:\n",
    "        plantation_desc = (\n",
    "            f\"La edad promedio de las plantaciones de agave en esta área fue de \"\n",
    "            f\"{record['avg_plantation_age']:.2f} años.\"\n",
    "        )\n",
    "        description_parts.append(plantation_desc)\n",
    "    \n",
    "    # Interpretación de nivel de riesgo basada en capturas promedio\n",
    "    risk_level = \"\"\n",
    "    if record['avg_captures'] < 5:\n",
    "        risk_level = \"bajo nivel de infestación\"\n",
    "    elif record['avg_captures'] < 15:\n",
    "        risk_level = \"nivel moderado de infestación\"\n",
    "    elif record['avg_captures'] < 30:\n",
    "        risk_level = \"nivel alto de infestación\"\n",
    "    else:\n",
    "        risk_level = \"nivel crítico de infestación\"\n",
    "    \n",
    "    risk_desc = f\"Este promedio de capturas sugiere un {risk_level} del picudo del agave en la zona.\"\n",
    "    description_parts.append(risk_desc)\n",
    "    \n",
    "    # Unir todas las partes\n",
    "    full_description = \" \".join(description_parts)\n",
    "    \n",
    "    return full_description\n",
    "\n",
    "\n",
    "def generate_rag_jsonl(df, output_file):\n",
    "    \"\"\"\n",
    "    Genera un archivo JSONL optimizado para sistemas RAG con descripciones\n",
    "    en lenguaje natural de las estadísticas de capturas de picudo.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_file : str\n",
    "        Ruta al archivo Excel con los datos\n",
    "    output_file : str\n",
    "        Ruta donde se guardará el archivo JSONL para RAG\n",
    "    \"\"\"\n",
    "      \n",
    "    # Extraer nombre del mes (month ya existe como int, solo necesitamos el nombre)\n",
    "    df['month_name'] = df['sampling_date'].dt.month_name()\n",
    "    \n",
    "    # Lista para almacenar todos los registros RAG\n",
    "    rag_records = []\n",
    "    \n",
    "    # 1. Agregación por ESTADO\n",
    "    print(\"Procesando agregaciones por Estado...\")\n",
    "    state_agg = df.groupby('state').agg({\n",
    "        'capture_count': ['mean', 'std', 'count', 'median', \n",
    "                         lambda x: np.percentile(x, 25),\n",
    "                         lambda x: np.percentile(x, 75)],\n",
    "        'year': ['min', 'max'],\n",
    "        'plantation_age': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    state_agg.columns = ['state', 'avg_captures', 'std_captures', 'observation_count',\n",
    "                        'median_captures', 'p25_captures', 'p75_captures',\n",
    "                        'year_min', 'year_max', 'avg_plantation_age']\n",
    "    \n",
    "    for _, row in state_agg.iterrows():\n",
    "        stats = {\n",
    "            'aggregation_level': 'state',\n",
    "            'state': row['state'],\n",
    "            'municipality': None,\n",
    "            'month': None,\n",
    "            'avg_captures': round(float(row['avg_captures']), 2),\n",
    "            'std_captures': round(float(row['std_captures']), 2) if pd.notna(row['std_captures']) else None,\n",
    "            'median_captures': round(float(row['median_captures']), 2),\n",
    "            'p25_captures': round(float(row['p25_captures']), 2),\n",
    "            'p75_captures': round(float(row['p75_captures']), 2),\n",
    "            'observation_count': int(row['observation_count']),\n",
    "            'year_range': f\"{int(row['year_min'])}-{int(row['year_max'])}\",\n",
    "            'avg_plantation_age': round(float(row['avg_plantation_age']), 2) if pd.notna(row['avg_plantation_age']) else None\n",
    "        }\n",
    "        \n",
    "        # Generar descripción en lenguaje natural\n",
    "        natural_description = generate_natural_language_description(stats)\n",
    "        \n",
    "        # Crear registro RAG\n",
    "        rag_record = {\n",
    "            'text': natural_description,\n",
    "            'metadata': {\n",
    "                'aggregation_level': stats['aggregation_level'],\n",
    "                'state': stats['state'],\n",
    "                'municipality': stats['municipality'],\n",
    "                'month': stats['month'],\n",
    "                'year_range': stats['year_range'],\n",
    "                'avg_captures': stats['avg_captures'],\n",
    "                'observation_count': stats['observation_count']\n",
    "            }\n",
    "        }\n",
    "        rag_records.append(rag_record)\n",
    "    \n",
    "    # 2. Agregación por MUNICIPIO\n",
    "    print(\"Procesando agregaciones por Municipio...\")\n",
    "    muni_agg = df.groupby(['state', 'municipality']).agg({\n",
    "        'capture_count': ['mean', 'std', 'count', 'median',\n",
    "                         lambda x: np.percentile(x, 25),\n",
    "                         lambda x: np.percentile(x, 75)],\n",
    "        'year': ['min', 'max'],\n",
    "        'plantation_age': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    muni_agg.columns = ['state', 'municipality', 'avg_captures', 'std_captures', \n",
    "                        'observation_count', 'median_captures', 'p25_captures', \n",
    "                        'p75_captures', 'year_min', 'year_max', 'avg_plantation_age']\n",
    "    \n",
    "    for _, row in muni_agg.iterrows():\n",
    "        stats = {\n",
    "            'aggregation_level': 'municipality',\n",
    "            'state': row['state'],\n",
    "            'municipality': row['municipality'],\n",
    "            'month': None,\n",
    "            'avg_captures': round(float(row['avg_captures']), 2),\n",
    "            'std_captures': round(float(row['std_captures']), 2) if pd.notna(row['std_captures']) else None,\n",
    "            'median_captures': round(float(row['median_captures']), 2),\n",
    "            'p25_captures': round(float(row['p25_captures']), 2),\n",
    "            'p75_captures': round(float(row['p75_captures']), 2),\n",
    "            'observation_count': int(row['observation_count']),\n",
    "            'year_range': f\"{int(row['year_min'])}-{int(row['year_max'])}\",\n",
    "            'avg_plantation_age': round(float(row['avg_plantation_age']), 2) if pd.notna(row['avg_plantation_age']) else None\n",
    "        }\n",
    "        \n",
    "        natural_description = generate_natural_language_description(stats)\n",
    "        \n",
    "        rag_record = {\n",
    "            'text': natural_description,\n",
    "            'metadata': {\n",
    "                'aggregation_level': stats['aggregation_level'],\n",
    "                'state': stats['state'],\n",
    "                'municipality': stats['municipality'],\n",
    "                'month': stats['month'],\n",
    "                'year_range': stats['year_range'],\n",
    "                'avg_captures': stats['avg_captures'],\n",
    "                'observation_count': stats['observation_count']\n",
    "            }\n",
    "        }\n",
    "        rag_records.append(rag_record)\n",
    "    \n",
    "    # 3. Agregación por MES\n",
    "    print(\"Procesando agregaciones por Mes...\")\n",
    "    month_agg = df.groupby(['month', 'month_name']).agg({\n",
    "        'capture_count': ['mean', 'std', 'count', 'median',\n",
    "                         lambda x: np.percentile(x, 25),\n",
    "                         lambda x: np.percentile(x, 75)],\n",
    "        'year': ['min', 'max'],\n",
    "        'plantation_age': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    month_agg.columns = ['month_num', 'month_name', 'avg_captures', 'std_captures',\n",
    "                        'observation_count', 'median_captures', 'p25_captures',\n",
    "                        'p75_captures', 'year_min', 'year_max', 'avg_plantation_age']\n",
    "    \n",
    "    month_agg = month_agg.sort_values('month_num')\n",
    "    \n",
    "    for _, row in month_agg.iterrows():\n",
    "        stats = {\n",
    "            'aggregation_level': 'month',\n",
    "            'state': None,\n",
    "            'municipality': None,\n",
    "            'month': row['month_name'],\n",
    "            'avg_captures': round(float(row['avg_captures']), 2),\n",
    "            'std_captures': round(float(row['std_captures']), 2) if pd.notna(row['std_captures']) else None,\n",
    "            'median_captures': round(float(row['median_captures']), 2),\n",
    "            'p25_captures': round(float(row['p25_captures']), 2),\n",
    "            'p75_captures': round(float(row['p75_captures']), 2),\n",
    "            'observation_count': int(row['observation_count']),\n",
    "            'year_range': f\"{int(row['year_min'])}-{int(row['year_max'])}\",\n",
    "            'avg_plantation_age': round(float(row['avg_plantation_age']), 2) if pd.notna(row['avg_plantation_age']) else None\n",
    "        }\n",
    "        \n",
    "        natural_description = generate_natural_language_description(stats)\n",
    "        \n",
    "        rag_record = {\n",
    "            'text': natural_description,\n",
    "            'metadata': {\n",
    "                'aggregation_level': stats['aggregation_level'],\n",
    "                'state': stats['state'],\n",
    "                'municipality': stats['municipality'],\n",
    "                'month': stats['month'],\n",
    "                'year_range': stats['year_range'],\n",
    "                'avg_captures': stats['avg_captures'],\n",
    "                'observation_count': stats['observation_count']\n",
    "            }\n",
    "        }\n",
    "        rag_records.append(rag_record)\n",
    "    \n",
    "    # 4. Agregación por ESTADO + MES\n",
    "    print(\"Procesando agregaciones por Estado + Mes...\")\n",
    "    state_month_agg = df.groupby(['state', 'month', 'month_name']).agg({\n",
    "        'capture_count': ['mean', 'std', 'count', 'median',\n",
    "                         lambda x: np.percentile(x, 25),\n",
    "                         lambda x: np.percentile(x, 75)],\n",
    "        'year': ['min', 'max'],\n",
    "        'plantation_age': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    state_month_agg.columns = ['state', 'month_num', 'month_name', 'avg_captures',\n",
    "                               'std_captures', 'observation_count', 'median_captures',\n",
    "                               'p25_captures', 'p75_captures', 'year_min', 'year_max',\n",
    "                               'avg_plantation_age']\n",
    "    \n",
    "    for _, row in state_month_agg.iterrows():\n",
    "        stats = {\n",
    "            'aggregation_level': 'state_month',\n",
    "            'state': row['state'],\n",
    "            'municipality': None,\n",
    "            'month': row['month_name'],\n",
    "            'avg_captures': round(float(row['avg_captures']), 2),\n",
    "            'std_captures': round(float(row['std_captures']), 2) if pd.notna(row['std_captures']) else None,\n",
    "            'median_captures': round(float(row['median_captures']), 2),\n",
    "            'p25_captures': round(float(row['p25_captures']), 2),\n",
    "            'p75_captures': round(float(row['p75_captures']), 2),\n",
    "            'observation_count': int(row['observation_count']),\n",
    "            'year_range': f\"{int(row['year_min'])}-{int(row['year_max'])}\",\n",
    "            'avg_plantation_age': round(float(row['avg_plantation_age']), 2) if pd.notna(row['avg_plantation_age']) else None\n",
    "        }\n",
    "        \n",
    "        natural_description = generate_natural_language_description(stats)\n",
    "        \n",
    "        rag_record = {\n",
    "            'text': natural_description,\n",
    "            'metadata': {\n",
    "                'aggregation_level': stats['aggregation_level'],\n",
    "                'state': stats['state'],\n",
    "                'municipality': stats['municipality'],\n",
    "                'month': stats['month'],\n",
    "                'year_range': stats['year_range'],\n",
    "                'avg_captures': stats['avg_captures'],\n",
    "                'observation_count': stats['observation_count']\n",
    "            }\n",
    "        }\n",
    "        rag_records.append(rag_record)\n",
    "    \n",
    "    # 5. Agregación por MUNICIPIO + MES\n",
    "    print(\"Procesando agregaciones por Municipio + Mes...\")\n",
    "    muni_month_agg = df.groupby(['state', 'municipality', 'month', 'month_name']).agg({\n",
    "        'capture_count': ['mean', 'std', 'count', 'median',\n",
    "                         lambda x: np.percentile(x, 25),\n",
    "                         lambda x: np.percentile(x, 75)],\n",
    "        'year': ['min', 'max'],\n",
    "        'plantation_age': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    muni_month_agg.columns = ['state', 'municipality', 'month_num', 'month_name',\n",
    "                              'avg_captures', 'std_captures', 'observation_count',\n",
    "                              'median_captures', 'p25_captures', 'p75_captures',\n",
    "                              'year_min', 'year_max', 'avg_plantation_age']\n",
    "    \n",
    "    for _, row in muni_month_agg.iterrows():\n",
    "        stats = {\n",
    "            'aggregation_level': 'municipality_month',\n",
    "            'state': row['state'],\n",
    "            'municipality': row['municipality'],\n",
    "            'month': row['month_name'],\n",
    "            'avg_captures': round(float(row['avg_captures']), 2),\n",
    "            'std_captures': round(float(row['std_captures']), 2) if pd.notna(row['std_captures']) else None,\n",
    "            'median_captures': round(float(row['median_captures']), 2),\n",
    "            'p25_captures': round(float(row['p25_captures']), 2),\n",
    "            'p75_captures': round(float(row['p75_captures']), 2),\n",
    "            'observation_count': int(row['observation_count']),\n",
    "            'year_range': f\"{int(row['year_min'])}-{int(row['year_max'])}\",\n",
    "            'avg_plantation_age': round(float(row['avg_plantation_age']), 2) if pd.notna(row['avg_plantation_age']) else None\n",
    "        }\n",
    "        \n",
    "        natural_description = generate_natural_language_description(stats)\n",
    "        \n",
    "        rag_record = {\n",
    "            'text': natural_description,\n",
    "            'metadata': {\n",
    "                'aggregation_level': stats['aggregation_level'],\n",
    "                'state': stats['state'],\n",
    "                'municipality': stats['municipality'],\n",
    "                'month': stats['month'],\n",
    "                'year_range': stats['year_range'],\n",
    "                'avg_captures': stats['avg_captures'],\n",
    "                'observation_count': stats['observation_count']\n",
    "            }\n",
    "        }\n",
    "        rag_records.append(rag_record)\n",
    "    \n",
    "    # Guardar todo en un archivo JSONL\n",
    "    print(f\"\\nGuardando {len(rag_records)} registros en {output_file}...\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for record in rag_records:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"✓ Archivo JSONL para RAG generado exitosamente: {output_file}\")\n",
    "    print(f\"\\nResumen de registros generados:\")\n",
    "    print(f\"  - Por estado: {len(state_agg)} registros\")\n",
    "    print(f\"  - Por municipio: {len(muni_agg)} registros\")\n",
    "    print(f\"  - Por mes: {len(month_agg)} registros\")\n",
    "    print(f\"  - Por estado + mes: {len(state_month_agg)} registros\")\n",
    "    print(f\"  - Por municipio + mes: {len(muni_month_agg)} registros\")\n",
    "    print(f\"  - TOTAL: {len(rag_records)} registros\")\n",
    "    \n",
    "    return rag_records\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configurar rutas de archivos\n",
    "    input_file = \"tu_archivo_datos.xlsx\"  # Cambia esto por tu archivo\n",
    "    output_file = \"capturas_picudo_rag.jsonl\"\n",
    "    \n",
    "    # Generar el archivo JSONL para RAG\n",
    "    records = generate_rag_jsonl(df, \"historic_data.jsonl\")\n",
    "    \n",
    "    # Mostrar algunos ejemplos\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EJEMPLOS DE DESCRIPCIONES EN LENGUAJE NATURAL:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Ejemplo de cada tipo de agregación\n",
    "    aggregation_types = ['state', 'municipality', 'month', 'state_month', 'municipality_month']\n",
    "    \n",
    "    for agg_type in aggregation_types:\n",
    "        example = next((r for r in records if r['metadata']['aggregation_level'] == agg_type), None)\n",
    "        if example:\n",
    "            print(f\"\\n{agg_type.upper().replace('_', ' ')}:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"TEXTO: {example['text']}\")\n",
    "            print(f\"\\nMETADATA: {json.dumps(example['metadata'], indent=2, ensure_ascii=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6bf094",
   "metadata": {},
   "source": [
    "# Embeddings nuevos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f858ac91",
   "metadata": {},
   "source": [
    "### Manual operativo modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0ab36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cargaron 18 paginas desde el Manual Operativo.\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el Manual Operativo como un documento para consulta del bot.\n",
    "loader = PyPDFLoader(r'C:/Users/Delbert/Documents/Maestria/Proyecto Integrador\\Avance 1/Tecnologico-Monterrey-Proyecto-Integrador-equipo-36/Telegram-Bot/Docs for embeddings/ManualOperativo_Agave_Modificado.pdf')\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Se cargaron {len(docs)} paginas desde el Manual Operativo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815177b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cargaron 303743 documentos de 11 archivos JSONL.\n"
     ]
    }
   ],
   "source": [
    "# Cargamos todos los text_features previamente generados que podrán ser consultados de nuevo.\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def load_jsonl_as_documents(jsonl_paths):\n",
    "\n",
    "    all_docs = []\n",
    "\n",
    "    for file_path in jsonl_paths:\n",
    "        path = Path(file_path)\n",
    "        if not path.exists():\n",
    "            print(f\"No se encontró el archivo siguiente: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line_num, line in enumerate(f, start=1):\n",
    "                try:\n",
    "                    record = json.loads(line.strip())\n",
    "                    # Usamos de nuevo la estructura de Alpaca\n",
    "                    text = (\n",
    "                        f\"Instrucción: {record.get('instruction', '')}\\n\"\n",
    "                        f\"Entrada: {record.get('input', '')}\\n\"\n",
    "                        f\"Respuesta: {record.get('output', '')}\"\n",
    "                    )\n",
    "\n",
    "                    # Tomamos metadata\n",
    "                    doc = Document(\n",
    "                        page_content=text,\n",
    "                        metadata={\n",
    "                            \"source\": path.name,\n",
    "                            \"line\": line_num\n",
    "                        }\n",
    "                    )\n",
    "                    all_docs.append(doc)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Se dio un error en la linea {line_num} en {path.name}: {e}\")\n",
    "                    continue\n",
    "\n",
    "    print(f\"Se cargaron {len(all_docs)} documentos de {len(jsonl_paths)} archivos JSONL.\")\n",
    "    return all_docs\n",
    "\n",
    "jsonl_files = [\n",
    "    \"Docs for embeddings/agave_allThings.jsonl\",\n",
    "    \"Docs for embeddings/agave_capture.jsonl\",\n",
    "    \"Docs for embeddings/agave_location.jsonl\",\n",
    "    \"Docs for embeddings/agave_plantation.jsonl\",\n",
    "    \"Docs for embeddings/agave_risk.jsonl\",\n",
    "    \"Docs for embeddings/agave_geospatial.jsonl\",\n",
    "    \"Docs for embeddings/agave_municipal_risk.jsonl\",\n",
    "    \"Docs for embeddings/agave_risk_temporal.jsonl\",\n",
    "    \"Docs for embeddings/agave_vulnerability.jsonl\",\n",
    "    \"Docs for embeddings/agave_weekly_anomaly.jsonl\",\n",
    "    \"Docs for embeddings/historic_data.jsonl\"\n",
    "]\n",
    "\n",
    "docs_jsonl = load_jsonl_as_documents(jsonl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f706ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = docs + docs_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb51f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Delbert\\AppData\\Local\\Temp\\ipykernel_10108\\605335807.py:11: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600, \n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \", \", \" \", \"\"],\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "chunked_docs = splitter.split_documents(all_documents)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "        'trust_remote_code': True\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        \"normalize_embeddings\": True,\n",
    "        \"batch_size\": 12\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e2f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(chunked_docs, embedding=embeddings)\n",
    "\n",
    "# Guardamos la vector store para cargas mas rapidas despues\n",
    "vectorstore.save_local(\"rag_faiss_store\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch311 (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
