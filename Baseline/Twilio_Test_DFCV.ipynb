{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5fcfe1",
   "metadata": {},
   "source": [
    "# Test de conectividad con Twilio-Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63da98",
   "metadata": {},
   "source": [
    "--------------------\n",
    "\n",
    "## Equipo 36\n",
    "\n",
    "| Nombre | Matrícula |\n",
    "| ------ | --------- |\n",
    "| André Martins Cordebello | A00572928 |\n",
    "| Enrique Eduardo Solís Da Costa | A00572678 |\n",
    "| Delbert Francisco Custodio Vargas | A01795613 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c66693",
   "metadata": {},
   "source": [
    "Para llevar a cabo este test de conectividad, hicimos uso de Twilio-Sandbox y la siguiente documentación:\n",
    "\n",
    "- https://ngrok.com/partners/twilio\n",
    "- https://www.twilio.com/docs/usage/tutorials/how-use-ngrok-windows-and-visual-studio-test-webhooks\n",
    "- https://www.twilio.com/docs/messaging/guides/webhook-request\n",
    "- https://www.twilio.com/docs/whatsapp/message-features#location-messages-with-whatsapp\n",
    "\n",
    "\n",
    "En los links anteriores es posible encontrar la forma de:\n",
    "\n",
    "1. Obtener los mensajes de texto por medio de un tuner creado con Ngrok\n",
    "2. Conectar este tunel a nuestro Kernel de Python por medio de Flask.\n",
    "3. Recibir y enviar mensajes por medio de WhatsApp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import gc\n",
    "from twilio.twiml.messaging_response import MessagingResponse\n",
    "from flask import Flask, request, Response\n",
    "from twilio.rest import Client\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=\"chatbot.env\")\n",
    "\n",
    "account_sid = os.getenv('account_sid_2')\n",
    "auth_token  = os.getenv('auth_token_2')\n",
    "FROM_NUMBER  = \"\" # FROM number de WahtsApp Sandbox de Twilio\n",
    "client = Client(account_sid, auth_token )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02851ca0",
   "metadata": {},
   "source": [
    "# Flujo principal para reporte de predios infestados con el gorgojo del agave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9168c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global session storage (temporary — resets if the app restarts)\n",
    "user_session = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f327b",
   "metadata": {},
   "source": [
    "Definimos una función para enviar mensajes sin formato a WhatsApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aea072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_whatsapp_message(From, To, message):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        msg = client.messages.create(\n",
    "            from_=From,\n",
    "            to=To,\n",
    "            body=message\n",
    "        )\n",
    "        print(f\"Message sent: {msg.sid}\")\n",
    "        return msg.sid\n",
    "    \n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Error sending message: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f09563",
   "metadata": {},
   "source": [
    "Probamos la función de envío."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c868727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_menu(From, To):\n",
    "    \n",
    "    menu_message = (\n",
    "        \"👋 *Bienvenido, será un gusto atenderte.*\\n\\n\"\n",
    "        \"¿Qué te interesa llevar a cabo?\\n\\n\"\n",
    "        \"🅰️ *Hacer un reporte de un predio infectado*\\n\"\n",
    "        \"🅱️ *Preguntar por información*\"\n",
    "        \"\\n\\n\"\n",
    "        \"Actualmente, solo estas 2 opciones tenemos disponibles.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        msg = client.messages.create(\n",
    "            from_=From,\n",
    "            to=To,\n",
    "            body=menu_message\n",
    "        )\n",
    "        print(f\"✅ Se envio correctamente el menu: {msg.sid}\")\n",
    "        return msg.sid\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error enviando menu: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_message_flow( sender, state, req ):\n",
    "\n",
    "\t# Cargamos el mensaje\n",
    "\tmessage = request.form.get(\"Body\", \"\").strip().lower() # Texto enviado por el usuario\n",
    "\tlabel   = request.form.get(\"Label\")  \t\t\t\t   # Label de la ubicacion enviada\n",
    "\tlat = request.form.get(\"Latitude\") \t\t\t\t\t   # Si envian ubicacion, cargamos la latitud\n",
    "\tlon = request.form.get('Longitude') \t\t\t\t   # Si envian ubicacion, cargamos la longitud\n",
    "\taddress = request.form.get('Address') \t\t\t\t   # Tomamos la dirección generada por WhatsApp\n",
    "\tphoto_url = req.form.get('MediaUrl0')\n",
    "\tnum_media = int(req.form.get('NumMedia', 0))\n",
    " \n",
    "\tresponse_text = \"\"\n",
    "\tnext_state = state\n",
    " \n",
    "\tif state == \"saludo\":\n",
    "\t\tif (message == \"a\") or (message == \"🅰️\"):\n",
    "\t\t\tresponse_text = (\"Gracias por tu proactividad. Te guiaré para reportar el predio. Primero, envía la **ubicación** del lote afectado.\")\n",
    "\t\t\tnext_state  = \"ask-location\"\n",
    "   \n",
    "\telif state == \"ask-location\":\n",
    "\t\tif lat and lon:\n",
    "\t\t\tuser_session[sender][\"data\"][\"lat\"]  = lat\n",
    "\t\t\tuser_session[sender][\"data\"][\"lon\"] = lon\n",
    "\t\t\tuser_session[sender][\"data\"][\"address\"]   = address\n",
    "\t\t\tresponse_text = (\n",
    "\t\t\t\t\"📍 Ubicación recibida *correctamente*.\\n\"\n",
    "\t\t\t\t\"Ahora, por favor envía una **foto** del lote o planta afectada.\"\n",
    "\t\t\t)\n",
    "\t\t\tnext_state = \"ask_photo\"\n",
    "\t\telse:\n",
    "\t\t\tresponse_text = (\"Parece que la información que enviaste no es correcta. Por favor, usa la función de ubicación de WhatsApp.\")\n",
    "\n",
    "\telif state == \"ask_photo\":\n",
    "\t\tif num_media > 0:\n",
    "\t\t\tphoto_url = req.form.get('MediaUrl0')\n",
    "\t\t\tuser_session[sender][\"data\"][\"photo_url\"] = photo_url\n",
    "\t\t\tresponse_text = (\n",
    "\t\t\t\t\"📸 Foto recibida correctamente.\\n\"\n",
    "\t\t\t\t\"Por último, clasifica el **nivel de riesgo** que observas: Alto, Medio o Bajo.\"\n",
    "\t\t\t)\n",
    "\t\t\tnext_state = \"ask_risk\"\n",
    "\t\telse:\n",
    "\t\t\tresponse_text = (\n",
    "\t\t\t\t\"⚠️ No se detectó una foto. Por favor envía una imagen del lote afectado.\"\n",
    "\t\t\t)\n",
    "\n",
    "\telif state == \"ask_risk\":\n",
    "    \n",
    "\t\tif message in [\"alta\", \"media\", \"baja\", \"alto\", \"medio\", \"bajo\"]:\n",
    "\t\t\tuser_session[sender][\"data\"][\"user_risk_assesment\"] = message.capitalize()\n",
    "\t\t\tdata = user_session[sender][\"data\"]\n",
    "\t\t\tresponse_text = (\n",
    "\t\t\t\tf\"✅ Gracias por tu reporte.\\n\"\n",
    "\t\t\t\tf\"📍 Ubicación: ({data['lat']}, {data['lon']})\\n\"\n",
    "\t\t\t\tf\"📸 Foto: Confirmada\\n\"\n",
    "\t\t\t\tf\"🚨 Riesgo: {data['user_risk_assesment']}\\n\\n\"\n",
    "\t\t\t\t\"¿Esta información es correcta? Responde con *Sí* o *No*.\"\n",
    "\t\t\t)\n",
    "\t\t\tnext_state = \"confirmation\"\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tresponse_text = (\n",
    "\t\t\t\t\"Por favor indica el nivel de riesgo como: Alta, Media o Baja.\"\n",
    "\t\t\t)\n",
    "\n",
    "\telif state == \"confirmation\":\n",
    "\t\tmsg = message.strip().lower()\n",
    "\n",
    "\t\tif re.search(r'^\\s*s[ií]\\s*$', msg):\n",
    "\t\t\tresponse_text = (\n",
    "\t\t\t\t\"🌾 Tu reporte ya fue registrado. ¡Gracias por tu colaboración!\"\n",
    "\t\t\t)\n",
    "\t\t\tprint(user_session[sender])\n",
    "\t\telif re.search(r'^\\s*no\\s*$', msg):\n",
    "\t\t\tresponse_text = \"❌ Entendido. Tu reporte no se registrará.\"\n",
    "\t\telse:\n",
    "\t\t\tresponse_text = \"Por el momento, solo podemos aceptar respuestas como 'Sí' o 'No'.\"\n",
    "\telse:\n",
    "\t\tresponse_text = (\"Por el momento, solo podemos aceptar respuestas como 'Sí', 'No', etc. \")\n",
    "\n",
    "\treturn response_text, next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ad300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reiniciamos user_session para hacer pruebas\n",
    "\n",
    "user_session = {}\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/reply_whatsapp\", methods=['POST'])\n",
    "\n",
    "def reply_whatsapp():\n",
    "\n",
    "\tsender  = request.form.get(\"From\") # Guardamos quien nos escribio\n",
    "\tmessage = request.form.get(\"Body\", \"\").strip().lower() # Tomamos el texto del mensaje para mostrarlo en la consola\n",
    "\tresp = MessagingResponse()\n",
    " \n",
    "\tprint(f\"Mensaje recibido: --> {message}\")\n",
    " \n",
    "\tif sender not in user_session:\n",
    "\t\tuser_session[sender] = {\"state\": \"saludo\",\n",
    "\t\t\t\t\t\t\t\t\"data\" : {\n",
    "\t\t\t\t\t\t\t\t\t\"lat\" : None, \n",
    "        \t\t\t\t\t\t\t\"lon\" : None,\n",
    "\t\t\t\t\t\t\t\t\t\"address\" : None,\n",
    "\t\t\t\t\t\t\t\t\t\"photo_url\" : None,\n",
    "\t\t\t\t\t\t\t\t\t\"user_risk_assesment\": None,\n",
    "\t\t\t\t\t\t\t\t\t\"price\" : None\n",
    "\t\t\t\t\t\t\t\t}\n",
    "              \t\t\t\t\t}\n",
    "\n",
    "\t\tsend_menu(FROM_NUMBER, sender)\n",
    "\t\tresp.message(\"Quedo a la espera de tu respuesta.\")\n",
    "\t\treturn Response(str(resp), mimetype=\"text/xml\")\n",
    "\n",
    "\t\n",
    "\tresponse_text, next_state = report_message_flow(sender, user_session[sender]['state'], request)\n",
    "\tuser_session[sender][\"state\"] = next_state\n",
    "\tresp.message(response_text)\n",
    "\t\n",
    "\treturn Response(str(resp), mimetype='text/xml')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tapp.run(port=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4228f0",
   "metadata": {},
   "source": [
    "# Flujo para llevar a cabo preguntas y responderlas con el LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import gc\n",
    "from twilio.twiml.messaging_response import MessagingResponse\n",
    "from flask import Flask, request, Response\n",
    "from twilio.rest import Client\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=\"chatbot.env\")\n",
    "\n",
    "account_sid = os.getenv('account_sid_2')\n",
    "auth_token  = os.getenv('auth_token_2')\n",
    "FROM_NUMBER  = \"\" # El FROM Number de WhatsApp va aqui\n",
    "client = Client(account_sid, auth_token )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5898e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "from peft import PeftModel\n",
    "\n",
    "# Modelo local\n",
    "model_path = \"D:/LLM Models/microsoft-phi-3-mini-4k-instruct\"\n",
    "\n",
    "# LoRA adapters\n",
    "lora_path = \"D:/LLM Models/agave_V001/agave_baseline_phi3_V01\"   \n",
    "\n",
    "# 8 bits de cuantizacion\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    ")\n",
    "\n",
    "# Usamos el tokenizer de Phi-3\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Implementamos los pesos LoRA a Phi-3\n",
    "model = PeftModel.from_pretrained(base_model, lora_path)\n",
    "\n",
    "# Colocamos el  modelo en evaluacion para que no cambie los pesos por cada prompt que\n",
    "# se le envíe\n",
    "model.eval()\n",
    "\n",
    "# Definimos el pipeline de nuevo\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=64,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d07c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def gen_prompt(tokenizer, sentence):\n",
    "    converted_sample = [{\"role\": \"user\", \"content\": sentence}]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        converted_sample, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate(model, tokenizer, prompt, max_new_tokens=64, skip_special_tokens=False):\n",
    "  \n",
    "  tokenized_input = tokenizer(\n",
    "  prompt, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
    "  model.eval()\n",
    "  gen_output = model.generate(**tokenized_input,\n",
    "  eos_token_id=tokenizer.eos_token_id,\n",
    "  max_new_tokens=max_new_tokens)\n",
    "  output = tokenizer.batch_decode(gen_output, skip_special_tokens=skip_special_tokens)\n",
    "\n",
    "  return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_llm( msg):\n",
    "    \n",
    "    prompt = gen_prompt(tokenizer, msg)\n",
    "    print(prompt)\n",
    "\n",
    "    answer = generate(model, tokenizer, prompt)\n",
    "    print(answer)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reiniciamos user_session para hacer pruebas\n",
    "\n",
    "user_session = {}\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/reply_whatsapp\", methods=['POST'])\n",
    "\n",
    "def reply_whatsapp():\n",
    "\n",
    "\tsender  = request.form.get(\"From\") # Guardamos quien nos escribio\n",
    "\tmessage = request.form.get(\"Body\", \"\").strip().lower() # Tomamos el texto del mensaje para mostrarlo en la consola\n",
    "\tresp = MessagingResponse()\n",
    " \n",
    "\tprint(f\"Mensaje recibido: --> {message}\")\n",
    "\n",
    "\t\n",
    "\tresponse_text = answer_with_llm(message)\n",
    "\tresp.message(response_text)\n",
    "\t\n",
    "\treturn Response(str(resp), mimetype='text/xml')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tapp.run(port=3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch311 (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
